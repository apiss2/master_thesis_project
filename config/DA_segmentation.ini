[DEFAULT]
task_name = DAsegmentation

# training
num_workers = 2
batch_size = 8
epochs = 100
log_interval = 25
monitor_metric = iou_score
model_save_name = best_model.pth

# loss
loss_seg = dice
loss_DA  = bcewithlogit

# optimizer
optimizer = adam
lr = 0.001
gamma = 0.2
decay_schedule = 50-80

# metrics
metrics = iou
metrics_D = accuracy-recall-precision-fscore

# model
model = Unet
encoder = efficientnet-b0
depth = 4
discriminator_channels = 128-64

# dataset
augmentation_setting_json = augmentation_settings/DAsegmentation_GoldAtlas_0.json

image_A_train = D:/datasets/GoldAtlas/train_valid/train_image_MR/
label_A_train = D:/datasets/GoldAtlas/train_valid/train_mask/
image_B_train = D:/datasets/GoldAtlas/train_valid/train_image_CT/
label_B_train = D:/datasets/GoldAtlas/train_valid/train_mask/

image_A_valid = D:/datasets/GoldAtlas/train_valid/valid_image_MR/
label_A_valid = D:/datasets/GoldAtlas/train_valid/valid_mask/
image_B_valid = D:/datasets/GoldAtlas/train_valid/valid_image_CT/
label_B_valid = D:/datasets/GoldAtlas/train_valid/valid_mask/

MR_mean = 0.249-0.249-0.249
MR_std  = 0.145-0.145-0.145
CT_mean = 0.485-0.485-0.485
CT_std  = 0.187-0.187-0.187

class_num = 1
label_type = binary_label


[low_memory]
batch_size=4

[deeplab]
model = DeepLabV3
depth = 4

discriminator_channels = 128-64-32

loss_DA  = bcewithlogit